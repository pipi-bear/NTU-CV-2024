{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lena.bmp', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling lena from 512x512 to 64x64\n",
    "> This part is the same as the previous homework 6\n",
    "\n",
    "1. binarize lena image as HW2\n",
    "2. use 8x8 blocks as a unit\n",
    "3. take top-most left pixel as downsampled data\n",
    "\n",
    "Note: Result is a 64x64 matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Binarize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_img = np.zeros(img.shape, np.int8)\n",
    "for i in range(img.shape[0]):\n",
    "    for j in range(img.shape[1]):\n",
    "        if img[i][j] >= 128:\n",
    "            binarized_img[i][j] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2, 3: Downsample the image\n",
    "\n",
    "First we initialize `downsampled_img` as a 64x64 matrix, with all elements being 0.\n",
    "\n",
    "Then we iterate through each 8x8 block in the binarized image, and take the top-most left pixel as the downsampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_img  = np.zeros((64, 64), np.int8)\n",
    "for i in range(0, 64):\n",
    "    for j in range(0, 64):\n",
    "        downsampled_img[i][j] = binarized_img[i*8][j*8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create marked image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yokoi operator\n",
    "\n",
    "> This Yokoi operator is implemented by adding little modifications from the previous homework 6.  \n",
    "> $\\rightarrow$ For more information (e.g. the definition of `h` and `f` functions, and the definition of Yokoi connectivity number) please refer to the previous homework 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### primitive functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(b, c, d, e):\n",
    "    if b == c and (d != b or e != b):\n",
    "        return 'q'\n",
    "    elif b == c and (d == b and e == b):\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Yokoi_f(a_1, a_2, a_3, a_4):\n",
    "    if a_1 == a_2 and a_2 == a_3 and a_3 == a_4 and a_4 == 'r':\n",
    "        return 5\n",
    "    else:\n",
    "        connectivity_number = 0\n",
    "        for a_i in [a_1, a_2, a_3, a_4]: \n",
    "            if a_i == 'q':\n",
    "                connectivity_number += 1\n",
    "        return connectivity_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Yokoi_operator function, we call the primitive functions above and do the following steps:  \n",
    "\n",
    "1. Initialize a matrix `Yokoi_result`with all elements being 0, having the same size as the downsampled image.  \n",
    "2. Iterate through each pixel in the downsampled image, and apply the Yokoi operator to determine the connectivity number.  \n",
    "3. Update the matrix with the connectivity number.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Yokoi_operator(img):\n",
    "    Yokoi_result = np.zeros(img.shape, np.int8)\n",
    "    rows, cols = img.shape\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if img[i][j] == 1:\n",
    "                x0 = img[i][j]\n",
    "                x1 = img[i][j+1] if j < cols-1 else 0\n",
    "                x2 = img[i-1][j] if i > 0 else 0\n",
    "                x3 = img[i][j-1] if j > 0 else 0\n",
    "                x4 = img[i+1][j] if i < rows-1 else 0\n",
    "                x5 = img[i+1][j+1] if i < rows-1 and j < cols-1 else 0\n",
    "                x6 = img[i-1][j+1] if i > 0 and j < cols-1 else 0\n",
    "                x7 = img[i-1][j-1] if i > 0 and j > 0 else 0\n",
    "                x8 = img[i+1][j-1] if i < rows-1 and j > 0 else 0\n",
    "\n",
    "                a1 = h(x0, x1, x6, x2)\n",
    "                a2 = h(x0, x2, x7, x3)\n",
    "                a3 = h(x0, x3, x8, x4)\n",
    "                a4 = h(x0, x4, x5, x1)\n",
    "\n",
    "                connectivity_number = Yokoi_f(a1, a2, a3, a4)\n",
    "                Yokoi_result[i][j] = connectivity_number\n",
    "    return Yokoi_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair relationship operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### primitive functions\n",
    "\n",
    "Note: To avoid using the same name as the primitive function `h` in the Yokoi operator, we name this function as `pair_h`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_h(a, m):\n",
    "    if a == m:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(x0, x1, x2, x3, x4, m):\n",
    "    if pair_h(x0, m) == 1 and pair_h(x1, m) + pair_h(x2, m) + pair_h(x3, m) + pair_h(x4, m) >= 1:\n",
    "        return 'p'\n",
    "    else:\n",
    "        return 'q'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_relationship_operator(Yokoi_result, m):\n",
    "    pair_result = np.zeros(Yokoi_result.shape, dtype = 'U1')\n",
    "    rows, cols = Yokoi_result.shape\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if Yokoi_result[i][j] == 1:\n",
    "                right = Yokoi_result[i][j+1] if j < cols-1 else 0\n",
    "                top = Yokoi_result[i-1][j] if i > 0 else 0\n",
    "                left = Yokoi_result[i][j-1] if j > 0 else 0\n",
    "                bottom = Yokoi_result[i+1][j] if i < rows-1 else 0\n",
    "                pair_result[i][j] = output(Yokoi_result[i][j], right, top, left, bottom, m)\n",
    "            else:\n",
    "                pair_result[i][j] = ' '\n",
    "\n",
    "    return pair_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# connected shrink operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def connected_shrink_h(b, c, d, e):\n",
    "    if b == c and (d != b or e != b):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def connected_shrink_operator(img, i, j):\n",
    "    rows, cols = img.shape\n",
    "    x0 = img[i][j]\n",
    "    x1 = img[i][j+1] if j < cols-1 else 0\n",
    "    x2 = img[i-1][j] if i > 0 else 0\n",
    "    x3 = img[i][j-1] if j > 0 else 0\n",
    "    x4 = img[i+1][j] if i < rows-1 else 0\n",
    "    x5 = img[i+1][j+1] if i < rows-1 and j < cols-1 else 0\n",
    "    x6 = img[i-1][j+1] if i > 0 and j < cols-1 else 0\n",
    "    x7 = img[i-1][j-1] if i > 0 and j > 0 else 0\n",
    "    x8 = img[i+1][j-1] if i < rows-1 and j > 0 else 0\n",
    "\n",
    "    a1 = connected_shrink_h(x0, x1, x6, x2)\n",
    "    a2 = connected_shrink_h(x0, x2, x7, x3)\n",
    "    a3 = connected_shrink_h(x0, x3, x8, x4)\n",
    "    a4 = connected_shrink_h(x0, x4, x5, x1)\n",
    "\n",
    "    if sum([a1, a2, a3, a4]) == 1:\n",
    "        return 0  \n",
    "    return 1  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# thinning operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thinning_operator(img, pair_result):\n",
    "    rows, cols = img.shape\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if pair_result[i][j] == 'p':\n",
    "                img[i][j] = connected_shrink_operator(img, i, j)\n",
    "    return img\n",
    "\n",
    "def iterative_thinning(downsampled_img):\n",
    "    previous_result = None\n",
    "    current_result = downsampled_img.copy()\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        iteration += 1\n",
    "        previous_result = current_result.copy()\n",
    "        \n",
    "        Yokoi_result = Yokoi_operator(current_result)\n",
    "        pair_result = pair_relationship_operator(Yokoi_result, 1)\n",
    "        current_result = thinning_operator(current_result, pair_result)\n",
    "        \n",
    "        if np.array_equal(previous_result, current_result):\n",
    "            print(f\"Converged after {iteration} iterations\")\n",
    "            break\n",
    "        \n",
    "        if iteration > 100:  # Safety limit\n",
    "            print(\"Reached maximum iterations\")\n",
    "            break\n",
    "    \n",
    "    return current_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main functinon\n",
    "\n",
    "In this part, we follow the following steps:  \n",
    "\n",
    "1. Create the marked image by applying Yokoi operator, pair relationship operator.\n",
    "    - Yokoi operator result: `Yokoi_result`\n",
    "    - Pair relationship operator result: `pair_result`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 7 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yokoi_result = Yokoi_operator(downsampled_img)\n",
    "np.savetxt('yokoi_result.txt', Yokoi_result, fmt='%d', delimiter=' ')\n",
    "\n",
    "pair_result = pair_relationship_operator(Yokoi_result, 1)\n",
    "np.savetxt('pair_result.txt', pair_result, fmt='%s', delimiter=' ')\n",
    "\n",
    "thinning_result = iterative_thinning(downsampled_img)\n",
    "np.savetxt('thinning_result.txt', thinning_result, fmt='%d', delimiter=' ')\n",
    "\n",
    "display_image = (thinning_result * 255).astype(np.uint8)\n",
    "cv2.imwrite('thinned_lena.bmp', display_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
